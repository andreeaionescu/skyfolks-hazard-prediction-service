{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hazard Predictions\n",
    "\n",
    "## The Challenge \n",
    "\n",
    "### Automatic Hazard Detection  on Transverse Cirrus Bands (TCB)\n",
    "#### Hurricanes | Tunderstorms | Atmospheric jets\n",
    "\n",
    "TCBs are bands of clouds oriented perpendicular to the atmospheric flow in which they are embedded. TCBs are often an indicator of strong turbulence and often associated with severe weather such as hurricanes and thunderstorms or atmospheric jets.\n",
    "\n",
    "Transverse Cirrus Bands Data: s3://impact-datashare/transverse_bands/\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda activate skyfolks-env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 10)\n",
    "plt.rcParams[\"figure.dpi\"] = 125\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "plt.rcParams['font.family'] = ['sans-serif']\n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "plt.style.use('ggplot')\n",
    "sns.set_style(\"whitegrid\", {'axes.grid': False})\n",
    "plt.rcParams['image.cmap'] = 'gray' # grayscale looks better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage.io import imread as imread\n",
    "from skimage.util import montage\n",
    "from PIL import Image\n",
    "montage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\n",
    "from skimage.color import label2rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Reading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REUSE dataset generator and augmentations from Examples\n",
    "Link: https://github.com/nasa/spaceapps-phenomena_detection/blob/dev/examples/ml_model_demo_1.ipynb\n",
    "\n",
    "Apply the logic to the Hurricane Dataset | Transverse Cirrus Bands (TCB)\n",
    "\n",
    "\n",
    "This is used to push subsets of input images in memory for Keras so that there is no out of memory error during Training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\n",
    "\n",
    "image_dir = Path('.') / 'data' / 'transverse_bands'\n",
    "mapping_file = Path('.') / 'data' / 'list_of_images.json'\n",
    "image_df = pd.read_json(mapping_file)\n",
    "\n",
    "image_df['is_hurricane'] = image_df['path'].map(lambda x: \"yes\" in x) \n",
    "\n",
    "image_df.sample(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_df['path'].map(lambda x: Path(x).exists()).value_counts()) # make sure everything is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df['is_hurricane'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df = image_df\n",
    "train_df.reset_index(inplace=True)\n",
    "print(train_df.shape[0], 'training images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df.insert(0, 'id', image_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_vec = np.stack(train_df[['id', 'path']], 0)\n",
    "train_y_vec = np.stack(train_df['is_hurricane'], 0)\n",
    "print(train_x_vec.shape, '->', train_y_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def get_image_pixels(imagePath):\n",
    "    im = Image.open(imagePath, 'r')\n",
    "    width, height = im.size\n",
    "    pixel_values = list(im.getdata())\n",
    "\n",
    "    return pixel_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df['image_rgb'] = [ get_image_pixels(x) for x in image_df['path'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "- Extract color features \n",
    "- reduce color noise\n",
    "- run PCA to sample the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "plt.rcParams[\"figure.figsize\"] = (6, 6)\n",
    "plt.rcParams[\"figure.dpi\"] = 200\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "plt.rcParams['font.family'] = ['sans-serif']\n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "plt.style.use('ggplot')\n",
    "sns.set_style(\"whitegrid\", {'axes.grid': False})\n",
    "plt.rcParams['image.cmap'] = 'viridis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage.io import imread\n",
    "from skimage.util import montage\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas() # hack progressbars into pandas\n",
    "montage_rgb = lambda x, **kwargs: np.stack([montage(x[:, :, :, i], **kwargs) for i in range(x.shape[3])], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satellite_dir = Path('data/transverse_bands')\n",
    "image_df = pd.DataFrame({'path': list(satellite_dir.glob('**/*.jp*g'))})\n",
    "image_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df['path'][0].__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the variable is_hurricane if \"yes\" string is in the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df['is_hurricane'] = image_df['path'].map(lambda x: \"yes\" in x.__str__()) \n",
    "image_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downgrading the IMAGE color spectrum\n",
    "\n",
    "- Currently have 2^8 | 8-bit  and 3 channel| Red, Green, Blue\n",
    "- Convert it to a 8-bit format to reduce the colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = Image.open(image_df['path'].iloc[2739]) # normal image\n",
    "# convert to 8bit color (animated GIF) and then back\n",
    "web_image = test_image.convert('P', palette='WEB', dither=None)\n",
    "few_color_image = web_image.convert('RGB')\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax1.imshow(test_image)\n",
    "ax2.imshow(few_color_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Unique colors before', len(set([tuple(rgb) for rgb in np.array(test_image).reshape((-1, 3))])))\n",
    "print('Unique colors after', len(set([tuple(rgb) for rgb in np.array(few_color_image).reshape((-1, 3))])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at the RGBs patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 6))\n",
    "for c_channel, c_name in enumerate(['red', 'green', 'blue']):\n",
    "    ax1.hist(np.array(test_image)[:, :, c_channel].ravel(), \n",
    "             color=c_name[0], \n",
    "             label=c_name, \n",
    "             bins=np.arange(256), \n",
    "             alpha=0.5)\n",
    "    ax2.hist(np.array(few_color_image)[:, :, c_channel].ravel(), \n",
    "             color=c_name[0], \n",
    "             label=c_name, \n",
    "             bins=np.arange(256), \n",
    "             alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_color = np.array(web_image.getpalette()).reshape((-1, 3))/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 6))\n",
    "ax1.imshow(few_color_image)\n",
    "counts, bins = np.histogram(web_image, bins=np.arange(256))\n",
    "for i in range(counts.shape[0]):\n",
    "    ax2.bar(bins[i], counts[i], color=idx_to_color[i])\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_xlabel('Color Id')\n",
    "ax2.set_ylabel('Pixel Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_count_feature(in_path):\n",
    "    raw_image = Image.open(in_path) \n",
    "    web_image = raw_image.convert('P', palette='WEB', dither=None)\n",
    "    counts, bins = np.histogram(np.array(web_image).ravel(), bins=np.arange(256))\n",
    "    return counts*1.0/np.prod(web_image.size) # normalize output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the images and extract color features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "image_df['color_features'] = image_df['path'].progress_map(color_count_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(20, 10))\n",
    "combined_features = np.stack(image_df['color_features'].values, 0)\n",
    "ax1.imshow(combined_features)\n",
    "ax1.set_title('Raw Color Counts')\n",
    "ax1.set_xlabel('Color')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_aspect(0.01)\n",
    "color_wise_average = np.tile(np.mean(combined_features, 0, keepdims=True), (combined_features.shape[0], 1)).clip(1/(128*128), 1)\n",
    "ax2.imshow(combined_features/color_wise_average, vmin=0.05, vmax=20)\n",
    "ax2.set_title('Normalized Color Counts')\n",
    "ax2.set_xlabel('Color')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_aspect(0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run PCA on the combined features\n",
    "- Helps visualize the data\n",
    "- Dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "xy_pca = PCA(n_components=2)\n",
    "xy_coords = xy_pca.fit_transform(combined_features)\n",
    "image_df['x'] = xy_coords[:, 0]\n",
    "image_df['y'] = xy_coords[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1,1, figsize=(15, 15))\n",
    "for c_group, c_row in image_df.groupby('is_hurricane'):\n",
    "    ax1.plot(c_row['x'], c_row['y'], '*', label=c_group)\n",
    "ax1.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show images grouped by color similarity\n",
    "- based on the principal components return by PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_xy_images(in_df, image_zoom=1):\n",
    "    fig, ax1 = plt.subplots(1,1, figsize=(10, 10))\n",
    "    artists = []\n",
    "    for _, c_row in in_df.iterrows():\n",
    "        c_img = Image.open(c_row['path']).resize((64, 64))\n",
    "        img = OffsetImage(c_img, zoom=image_zoom)\n",
    "        ab = AnnotationBbox(img, (c_row['x'], c_row['y']), xycoords='data', frameon=False)\n",
    "        artists.append(ax1.add_artist(ab))\n",
    "    ax1.update_datalim(in_df[['x', 'y']])\n",
    "    ax1.autoscale()\n",
    "    ax1.axis('off')\n",
    "show_xy_images(image_df.sample(200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Extracted Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df['path'] = image_df['path'].map(str) # saving pathlib objects causes problems\n",
    "image_df.to_json('color_features.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df['data_split'] = 'train_another'\n",
    "image_df['data_split'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into test/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df = image_df.query('data_split==\"train_another\"')\n",
    "train_df.reset_index(inplace=True)\n",
    "print(train_df.shape[0], 'training images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_vec = np.stack(train_df['color_features'].values, 0)\n",
    "train_y_vec = np.stack(train_df['is_hurricane'], 0)\n",
    "print(train_x_vec.shape, '->', train_y_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper function to show model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\n",
    "\n",
    "def show_model_results(in_model, use_split=None, plot_type='swarm'):\n",
    "    fig, m_axs = plt.subplots(4, 2, figsize=(15, 30))\n",
    "    m_axs = m_axs.flatten()\n",
    "    all_rows = []\n",
    "    ax1 = m_axs[0]\n",
    "    \n",
    "    if use_split is None:\n",
    "        cur_df = image_df.copy()\n",
    "    else:\n",
    "        cur_df = image_df.query('data_split==\"{}\"'.format(use_split)) \n",
    "    \n",
    "    for c_split, example_df in cur_df.groupby('data_split'):\n",
    "        example_df = example_df.reset_index()\n",
    "        x_vec = np.stack(example_df['color_features'].values, 0)\n",
    "        y_vec = np.stack(example_df['is_hurricane'], 0)\n",
    "\n",
    "        valid_pred = in_model.predict(x_vec)\n",
    "        tpr, fpr, _ = roc_curve(y_vec[:], valid_pred[:])\n",
    "        auc = roc_auc_score(y_vec[:], valid_pred[:])\n",
    "        acc = accuracy_score(y_vec[:], valid_pred[:]>0.5)\n",
    "        ax1.plot(tpr, fpr, '.-', label='{}, AUC {:0.2f}, Accuracy: {:2.0%}'.format(c_split, auc, acc))\n",
    "        all_rows += [pd.DataFrame({'class': y_vec[:], 'prediction': np.clip(valid_pred[:], 0, 1), 'type': 'is_hurricane', \n",
    "                                  'split': c_split})]\n",
    "    \n",
    "    c_all_df = pd.concat(all_rows)\n",
    "        \n",
    "    # show example images\n",
    "    ax1.legend()\n",
    "    for (_, c_row), (c_ax) in zip(\n",
    "        example_df.sample(m_axs.shape[0]).iterrows(), \n",
    "                               m_axs[1:-1]):\n",
    "        \n",
    "        c_ax.imshow(imread(c_row['path']))\n",
    "        t_yp = in_model.predict(np.expand_dims(c_row['color_features'], 0))\n",
    "        c_ax.set_title('Class: {}\\n Is Hurricane Prediction: {:2.2%}'.format(c_row['is_hurricane'], t_yp[0]))\n",
    "        c_ax.axis('off')\n",
    "        \n",
    "        t_y = np.array(c_row['is_hurricane'])\n",
    "    \n",
    "    # nice dataframe of output\n",
    "    \n",
    "    ax1 = m_axs[-1]\n",
    "    if plot_type=='swarm':\n",
    "        # prevent overplotting\n",
    "        sns.swarmplot(data=c_all_df.sample(500) if c_all_df.shape[0]>1000 else c_all_df,\n",
    "                      hue='class', \n",
    "                      y='prediction', \n",
    "                      x='type', \n",
    "                      size=2.0, \n",
    "                      ax=ax1)\n",
    "    elif plot_type=='box':\n",
    "        sns.boxplot(data=c_all_df, hue='class', y='prediction', x='type', ax=ax1)\n",
    "    elif plot_type=='violin':\n",
    "        sns.violinplot(data=c_all_df, hue='class', y='prediction', x='type', ax=ax1)\n",
    "    ax1.set_ylim(-0.05, 1.05)\n",
    "    return c_all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNeighbors Regressor \n",
    "Nearest Neighbor works by finding the most similar case from the training data using the feature vector. We can directly visualize this by showing which training image was being looked at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor(n_neighbors=1)\n",
    "knn.fit(train_x_vec, train_y_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_model_results(knn, None, plot_type='box');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dig deeper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, m_axs = plt.subplots(6, 4, figsize=(30, 40))\n",
    "dummy_web_image = Image.new(size=(1,1), mode='RGB').convert('P', palette='web')\n",
    "\n",
    "for (c_ax, c_feat_ax, d_ax, d_feat_ax), (_, c_row) in zip(m_axs, \n",
    "                            image_df.sample(m_axs.shape[0], random_state=2018).iterrows()):\n",
    "    \n",
    "    query_img = Image.open(c_row['path'])\n",
    "    idx_to_color = np.array(query_img.convert('P', palette='web').getpalette()).reshape((-1, 3))/255.0\n",
    "    c_ax.imshow(query_img)\n",
    "    c_ax.set_title(c_row['path'][:25])\n",
    "    c_ax.axis('off')\n",
    "    counts, bins = np.histogram(np.ravel(query_img.convert('P', palette='web')), \n",
    "                                bins=np.arange(256))\n",
    "    \n",
    "    for i in range(counts.shape[0]):\n",
    "        c_feat_ax.bar(bins[i], counts[i], color=idx_to_color[i], edgecolor='k', linewidth=0.1)\n",
    "    c_feat_ax.set_yscale('log')\n",
    "    c_feat_ax.set_xlabel('Color Id')\n",
    "    c_feat_ax.set_ylabel('Pixel Count')\n",
    "    c_feat_ax.set_title('Feature Vector')\n",
    "    \n",
    "    dist, idx = knn.kneighbors(np.expand_dims(c_row['color_features'], 0))\n",
    "    m_row = train_df.iloc[idx[0][0]]\n",
    "    matched_img = Image.open(m_row['path'])\n",
    "    \n",
    "    d_ax.imshow(matched_img)\n",
    "    d_ax.set_title('Closest Match\\n{}\\nDistance: {:2.1%}'.format(m_row['path'][:25], dist[0][0]))\n",
    "    d_ax.axis('off')\n",
    "    \n",
    "    counts, bins = np.histogram(np.ravel(matched_img.convert('P', palette='web')), \n",
    "                                bins=np.arange(256))\n",
    "    \n",
    "    for i in range(counts.shape[0]):\n",
    "        d_feat_ax.bar(bins[i], counts[i], color=idx_to_color[i], edgecolor='k', linewidth=0.1)\n",
    "    d_feat_ax.set_yscale('log')\n",
    "    d_feat_ax.set_xlabel('Color Id')\n",
    "    d_feat_ax.set_ylabel('Pixel Count')\n",
    "    c_feat_ax.set_title('Matched Feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_model_results(knn);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Try other Model\n",
    "\n",
    "- RandomForest\n",
    "- XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_pipe = make_pipeline(RobustScaler(), RandomForestRegressor(n_estimators=200))\n",
    "rf_pipe.fit(train_x_vec, train_y_vec)\n",
    "show_model_results(rf_pipe);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xg_pipe = make_pipeline(RobustScaler(), \n",
    "                        XGBRegressor(objective='reg:linear'))\n",
    "xg_pipe.fit(train_x_vec, train_y_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_model_results(xg_pipe);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Test and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_vec = np.stack(train_df['color_features'].values, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get first Element\n",
    "\n",
    "predictInput = train_df[train_df.index == 5002]\n",
    "predictInput.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_x_vec = np.stack(predictInput['color_features'].values, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(knn.predict(predict_x_vec));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf_pipe.predict(predict_x_vec));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xg_pipe.predict(predict_x_vec));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model_filename = \"knn_hurricane.model\"\n",
    "\n",
    "models = {'knn': knn, 'rf_pipe': rf_pipe, 'xg_pipe': xg_pipe}\n",
    "\n",
    "pickle._dump(models, open(model_filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "loaded_classifiers = pickle.load(open(model_filename, 'rb'))\n",
    "\n",
    "# print(loaded_classifiers['rf_pipe'].predict(predict_x_vec));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAZAR-PREDICTION-SERVICE\n",
    "\n",
    "##### Logic steps\n",
    "\n",
    "1. Expose Endpoint using Flask\n",
    "\n",
    "2. Receive Request in JSON\n",
    "\n",
    "3. Call MODIS to retrieve image for X,Y\n",
    "\n",
    "4. Run Image by previous Model\n",
    "\n",
    "5. Return Results in JSON\n",
    "\n",
    "\n",
    "Contract Request Body:\n",
    "```json\n",
    "{\n",
    "    latitude: 14.021,\n",
    "    longitude: -124.034,\n",
    "    predict: [ \"hurricane\" ]\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flask Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "from flask import Flask\n",
    "from flask import request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_count_feature(in_path):\n",
    "    raw_image = Image.open(in_path) \n",
    "    web_image = raw_image.convert('P', palette='WEB', dither=None)\n",
    "    counts, bins = np.histogram(np.array(web_image).ravel(), bins=np.arange(256))\n",
    "    return counts*1.0/np.prod(web_image.size) # normalize output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "@app.after_request\n",
    "def after_request(response):\n",
    "    response.headers.add('Access-Control-Allow-Origin', '*')\n",
    "    response.headers.add('Access-Control-Allow-Headers', 'Content-Type,Authorization')\n",
    "    response.headers.add('Access-Control-Allow-Methods', 'GET,PUT,POST,DELETE')\n",
    "    return response\n",
    "\n",
    "@app.route('/hazard/predict', methods=['POST'])\n",
    "def power():\n",
    "    if request.headers['Content-Type'] == 'application/json':\n",
    "        return process_request(request.json)\n",
    "    else:\n",
    "        return response(\"Json record not found in request\", 415)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Service\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:8777/ (Press CTRL+C to quit)\n",
      "192.168.1.112 - - [04/Oct/2020 14:04:28] \"\u001b[37mOPTIONS /hazard/predict HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request received: \n",
      "{'latitude': 51.67030573742217, 'longitude': -50.87328749999999, 'predict': ['hurricane']}\n",
      "Calculating Square Shape...\n",
      "Shape:  {'lower_latitude': 46.67030573742217, 'left_longitude': -55.87328749999999, 'higher_latitude': 56.67030573742217, 'right_longitude': -45.87328749999999}\n",
      "Retrieve & download the MODIS image based on (X,Y,Z,K) parameters\n",
      "1376 2220\n",
      "Image PATH:  img/modis_hazard_c84abb3c598b408dbc26d548b1d77e6b.png  \n",
      "\n",
      "Predict if in the image is an Hurricane\n",
      "img/modis_hazard_c84abb3c598b408dbc26d548b1d77e6b.png\n",
      "0    img/modis_hazard_c84abb3c598b408dbc26d548b1d77...\n",
      "Name: path, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "progress-bar:   0%|                                                                                                                                                    | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.74029698e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 5.14286088e-03\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.06301069e-02 3.88448041e-03 5.23779594e-06 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 3.27362246e-07\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.48331107e-02 3.37117641e-03\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.04222318e-02 1.28067384e-02 2.12785460e-05 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 2.94626021e-06 8.21679237e-05\n",
      " 8.46886130e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 3.60098471e-06 3.92834695e-06\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.16540960e-04 1.07964069e-03 5.79103813e-04 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 3.00584014e-03\n",
      " 1.24970537e-02 9.78485753e-04 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 6.54724492e-07 1.71341400e-03 1.27016551e-03\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.34218521e-05\n",
      " 2.52330819e-03 1.12285250e-03 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 2.61496962e-03 4.46129269e-02\n",
      " 4.32936570e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 5.70526922e-03 8.48195579e-04 9.82086738e-07\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 3.27362246e-07 5.54224282e-03\n",
      " 5.70265032e-04 3.27362246e-07 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 7.92543997e-04 1.53210442e-01 5.22473418e-02\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 5.52148806e-02 1.49491279e-01 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 6.54724492e-07 5.18957548e-02 1.25949023e-01\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.14558454e-01 1.39716897e-01 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress-bar: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.38it/s]\n",
      "192.168.1.112 - - [04/Oct/2020 14:04:37] \"\u001b[37mPOST /hazard/predict HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index                                               path is_hurricane  \\\n",
      "0   123  img/modis_hazard_c84abb3c598b408dbc26d548b1d77...        False   \n",
      "\n",
      "                                      color_features data_split  \n",
      "0  [0.005740296983029541, 0.0, 0.0, 0.0, 0.0, 0.0...    predict  \n",
      "Probability of hurricane:\n",
      "[0.11]\n",
      "Response:  {'latitude': 51.67030573742217, 'longitude': -50.87328749999999, 'predicted': [{'hazardType': 'hurricane', 'probability': 0.11}]}\n"
     ]
    }
   ],
   "source": [
    "app.run(host='0.0.0.0', port=8777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### curl example to test endpoint\n",
    "\n",
    "\n",
    "<code>curl -d '{\"latitude\":-26.055, \"longitude\":43.273, \"predict\": [ \"hurricane\" ]}' -H \"Content-Type: application/json\" -X POST http://localhost:8777/hazard/predict\n",
    "</code>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_request(requestJson):\n",
    "    print(\"Request received: \")\n",
    "    print(requestJson)\n",
    "    \n",
    "    # Calculate square shape from the X,Y of the click\n",
    "    print(\"Calculating Square Shape...\")\n",
    "    squareShape = calculate_square_shape(requestJson['latitude'],requestJson['longitude'])\n",
    "    print(\"Shape: \", squareShape)\n",
    "    \n",
    "    # Retrieve & download the MODIS image based on (X,Y,Z,K) parameters\n",
    "    print(\"Retrieve & download the MODIS image based on (X,Y,Z,K) parameters\")\n",
    "    imagePath = retrieve_modis_image(squareShape['lower_latitude'], squareShape['left_longitude'],\n",
    "        squareShape['higher_latitude'], squareShape['right_longitude'])\n",
    "    print(\"Image PATH: \",imagePath,\" \\n\")\n",
    "    \n",
    "    # Predict if in the image is an Hurricane    \n",
    "    print(\"Predict if in the image is an Hurricane\")\n",
    "    response = predict_is_hurricane(requestJson['latitude'], requestJson['longitude'], imagePath)\n",
    "    \n",
    "    # Response\n",
    "    print(\"Response: \",response)\n",
    "    return response\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Square shape from point lattitudeX, longitudeY\n",
    "\n",
    "Result Dimensions: [lower_latitude, left_longitude, higher_latitude, right_longitude]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_square_shape(lattX,longY):\n",
    "    clickDistanceToEdge = 5; # measured in coordinate degrees\n",
    "    \n",
    "    lower_latitude = lattX - clickDistanceToEdge\n",
    "    left_longitude = longY - clickDistanceToEdge\n",
    "    higher_latitude = lattX + clickDistanceToEdge\n",
    "    right_longitude = longY + clickDistanceToEdge\n",
    "    \n",
    "    result = {\"lower_latitude\":lower_latitude, \"left_longitude\":left_longitude, \n",
    "              \"higher_latitude\":higher_latitude, \"right_longitude\":right_longitude}\n",
    "    \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve MODIS image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1302cae4-39d3-4656-82ad-d8a7306869fc\n",
      "f2f8d99800c040f4a5b71bb3df970894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'modis_hazard_c6449644896245c980c1c23147844287.png'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la=51.46162974683544\n",
    "lo=-22.94768591772153\n",
    "\n",
    "import uuid\n",
    "uuid.uuid4()\n",
    "\n",
    "print( str(uuid.uuid4()))\n",
    "\n",
    "print( uuid.uuid4().hex)\n",
    "\n",
    "imageTest = \"modis_hazard_%s.png\" % (uuid.uuid4().hex)\n",
    "\n",
    "imageTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import uuid\n",
    "\n",
    "from io import BytesIO\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "\n",
    "URL = \"https://gibs.earthdata.nasa.gov/wms/epsg4326/best/wms.cgi?SERVICE=WMS&REQUEST=GetMap&layers=MODIS_Aqua_CorrectedReflectance_TrueColor&version=1.3.0&crs=EPSG:4326&transparent=false&width={}&height={}&bbox={}&format=image/tiff&time={}\"\n",
    "KM_PER_DEG_AT_EQ = 111.\n",
    "\n",
    "\n",
    "# Note: Be careful with the resolution and extent. higher resolution with bigger extent images will be huge\n",
    "# and probably not load. For the dataset we have 0.25 might be more than enough.\n",
    "def calculate_width_height(extent, resolution):\n",
    "    \"\"\"\n",
    "    extent: [lower_latitude, left_longitude, higher_latitude, right_longitude],\n",
    "        EG: [51.46162974683544,-22.94768591772153,53.03698575949367,-20.952234968354432]\n",
    "    resolution: represents the pixel resolution,\n",
    "        i.e. km/pixel. Should be a value from this list: [0.03, 0.06, 0.125, 0.25, 0.5, 1, 5, 10]\n",
    "    \"\"\"\n",
    "    lats = extent[::2]\n",
    "    lons = extent[1::2]\n",
    "    km_per_deg_at_lat = KM_PER_DEG_AT_EQ * np.cos(np.pi * np.mean(lats) / 180.)\n",
    "    width = int((lons[1] - lons[0]) * km_per_deg_at_lat / resolution)\n",
    "    height = int((lats[1] - lats[0]) * KM_PER_DEG_AT_EQ / resolution)\n",
    "    print(width, height)\n",
    "    return width, height\n",
    "\n",
    "\n",
    "def modis_url(time, extent, resolution):\n",
    "    \"\"\"\n",
    "    time: utc time in iso format EG: 2020-02-19T00:00:00Z\n",
    "    extent: [lower_latitude, left_longitude, higher_latitude, right_longitude],\n",
    "        EG: [51.46162974683544,-22.94768591772153,53.03698575949367,-20.952234968354432]\n",
    "    resolution: represents the pixel resolution,\n",
    "        i.e. km/pixel. Should be a value from this list: [0.03, 0.06, 0.125, 0.25, 0.5, 1, 5, 10]\n",
    "    \"\"\"\n",
    "    width, height = calculate_width_height(extent, resolution)\n",
    "    extent = ','.join(map(lambda x: str(x), extent))\n",
    "    return width, height, URL.format(width, height, extent, time)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def retrieve_modis_image(x,y,z,k):\n",
    "    width, height, url = modis_url('2020-10-03T00:00:00Z',\n",
    "                               [x,y,z,k],\n",
    "                               0.5)\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    \n",
    "    #Unique ID generated\n",
    "    id = uuid.uuid4().hex\n",
    "\n",
    "    imagePath = \"img/modis_hazard_%s.png\" % (id)\n",
    "    \n",
    "    img.save(imagePath)\n",
    "    \n",
    "    return imagePath\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3100 2673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'img/modis_hazard_9634b8ef7a2d4d18bcda3b036d5eae0d.png'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test MODIS\n",
    "# {'lower_latitude': -56.055, 'left_longitude': 13.273000000000003, 'higher_latitude': 3.9450000000000003, 'right_longitude': 73.273}\n",
    "\n",
    "retrieve_modis_image(-26.0553, 28.4103, -14.0135, 43.2748)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Square Shape...\n",
      "Shape:  {'lower_latitude': -23.123, 'left_longitude': 30.122999999999998, 'higher_latitude': -13.123000000000001, 'right_longitude': 40.123}\n",
      "Retrieve & download the MODIS image based on (X,Y,Z,K) parameters\n",
      "2109 2220\n",
      "Image PATH:  img/modis_hazard_d2f8cfded4c54c45b995fe190f7e2ff5.png  \n",
      "\n"
     ]
    }
   ],
   "source": [
    " # Calculate square shape from the X,Y of the click\n",
    "print(\"Calculating Square Shape...\")\n",
    "squareShape = calculate_square_shape(-18.123,35.123)\n",
    "print(\"Shape: \", squareShape)\n",
    "\n",
    "# Retrieve & download the MODIS image based on (X,Y,Z,K) parameters\n",
    "print(\"Retrieve & download the MODIS image based on (X,Y,Z,K) parameters\")\n",
    "imagePath = retrieve_modis_image(squareShape['lower_latitude'], squareShape['left_longitude'],\n",
    "    squareShape['higher_latitude'], squareShape['right_longitude'])\n",
    "print(\"Image PATH: \",imagePath,\" \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict if hurricane \n",
    "- Use existing model on the image downloaded\n",
    "- Decompose the image so that it fits the model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "newId = len(train_df)+1\n",
    "\n",
    "train_df= train_df.append({'index': newId, 'path':'img/modis_hazard_3e8429697ddd434bb0ad2ddd3063a9d9.png', 'is_hurricane': False, 'data_split':'predict' }, ignore_index=True)\n",
    "\n",
    "train_df.iloc[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_image = Image.open(train_df.iloc[-1]['path'])\n",
    "raw_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df['index'] == newId]['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDF = train_df[train_df['index'] == newId]\n",
    "newDF\n",
    "newDF['color_features'] = newDF['path'].progress_map(color_count_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tqdm\\std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "\n",
    "def decompose_img(imagePath):\n",
    "    mock_df = pd.DataFrame( columns=['index', 'path', 'is_hurricane','color_features','data_split'])\n",
    "\n",
    "    newId = 123\n",
    "    raw_image = Image.open(imagePath)\n",
    "    \n",
    "    mock_df= mock_df.append({'index': newId, 'path':str(imagePath), 'is_hurricane': False, 'data_split':'predict' }, ignore_index=True)\n",
    "\n",
    "    mock_df.iloc[-1]\n",
    "    \n",
    "    newDF = mock_df[mock_df['index'] == newId]\n",
    "    \n",
    "    print(np.array(color_count_feature(imagePath)))\n",
    "#     newDF['color_features'] = np.array(color_count_feature(imagePath))\n",
    "    newDF['color_features'] = newDF['path'].progress_map(color_count_feature)\n",
    "    \n",
    "    return newDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def predict_is_hurricane(latitudeX, longitudeY, imagePath):\n",
    "    #Load model from saved file\n",
    "    model_filename = \"knn_hurricane.model\"\n",
    "        \n",
    "    loaded_classifiers = pickle.load(open(model_filename, 'rb'))\n",
    "\n",
    "    #Decompose image colour features - RGB\n",
    "    newDF = decompose_img(imagePath)\n",
    "    print(newDF)\n",
    "    predict_x_vec = np.stack(newDF['color_features'], 0)\n",
    "    predicted_probability = loaded_classifiers['rf_pipe'].predict(predict_x_vec)\n",
    "    \n",
    "    #Pass the image as input to the model- get probabilty\n",
    "    print(\"Probability of hurricane:\");\n",
    "    predicted_probability = loaded_classifiers['rf_pipe'].predict(predict_x_vec)\n",
    "    print(predicted_probability);\n",
    "    \n",
    "    #Format Response\n",
    "    response = { \"latitude\": latitudeX, \"longitude\": longitudeY, \"predicted\": [ { \"hazardType\": \"hurricane\", \"probability\": predicted_probability[0] }]}\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress-bar: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:54:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.2.0/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "img/modis_hazard_3e8429697ddd434bb0ad2ddd3063a9d9.png\n",
      "0    img/modis_hazard_3e8429697ddd434bb0ad2ddd3063a...\n",
      "Name: path, dtype: object\n",
      "[6.57238332e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.45964979e-03\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 2.21191053e-03 1.03468846e-03 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 3.92363366e-02 3.69980309e-02\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 8.08139197e-02 1.52384271e-01 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 2.63951137e-06 2.63951137e-06\n",
      " 5.80692502e-05 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.36198787e-03 2.13800421e-03\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 8.66023682e-03 5.89059753e-02 1.79565959e-02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 4.05481737e-02\n",
      " 8.59794435e-02 3.58445645e-03 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 5.22623252e-03 2.73981281e-03\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 2.63951137e-06 8.71038753e-05 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 3.88008172e-04\n",
      " 3.46567843e-02 1.03627217e-02 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.68796752e-02 1.35918999e-01\n",
      " 7.61499031e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 6.54334870e-03 7.68097810e-04 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 2.37556024e-05 2.03506327e-02\n",
      " 1.22473328e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 2.33068854e-03 1.01375713e-01 1.25324000e-02\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.13393409e-02 2.26364495e-02 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 5.27902275e-06 1.33876017e-02 1.89279361e-02\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.53698747e-02 2.53129141e-02 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  index                                               path is_hurricane  \\\n",
      "0   123  img/modis_hazard_3e8429697ddd434bb0ad2ddd3063a...        False   \n",
      "\n",
      "                                      color_features data_split  \n",
      "0  [0.0006572383320399728, 0.0, 0.0, 0.0, 0.0, 0....    predict  \n",
      "Probability of hurricane:\n",
      "[0.195]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test predict function\n",
    "response = predict_is_hurricane(12.32,123.33,'img/modis_hazard_3e8429697ddd434bb0ad2ddd3063a9d9.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
