{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hazard Predictions\n",
    "\n",
    "## The Challenge \n",
    "\n",
    "### Automatic Hazard Detection  on Transverse Cirrus Bands (TCB)\n",
    "#### Hurricanes | Tunderstorms | Atmospheric jets\n",
    "\n",
    "TCBs are bands of clouds oriented perpendicular to the atmospheric flow in which they are embedded. TCBs are often an indicator of strong turbulence and often associated with severe weather such as hurricanes and thunderstorms or atmospheric jets.\n",
    "\n",
    "Transverse Cirrus Bands Data: s3://impact-datashare/transverse_bands/\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import rasterio\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import imgaug as ia\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from IPython.display import clear_output\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    ")\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Dense,\n",
    "    Conv2D,\n",
    "    UpSampling2D,\n",
    "    MaxPooling2D,\n",
    "    Dropout,\n",
    "    concatenate,\n",
    "    Conv2DTranspose,\n",
    "    BatchNormalization,\n",
    "    Flatten\n",
    ")\n",
    "\n",
    "ia.seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Install rasterio package Journey\n",
    "\n",
    "1.Pre-required\n",
    "```\n",
    "pip install wheel\n",
    "pip install pipwin\n",
    "\n",
    "pipwin install numpy\n",
    "pipwin install pandas\n",
    "pipwin install shapely\n",
    "pipwin install gdal\n",
    "pipwin install fiona\n",
    "pipwin install pyproj\n",
    "pipwin install six\n",
    "pipwin install rtree\n",
    "\n",
    "pip install --user geopandas\n",
    "```\n",
    "\n",
    "2.Second install Fiona\n",
    "Download Fiona distribution https://www.lfd.uci.edu/~gohlke/pythonlibs/#fiona\n",
    "```\n",
    "pip install C:\\Users\\libs\\Fiona-1.8.17-cp39-cp39-win_amd64.whl\n",
    "```\n",
    "\n",
    "3.And finally\n",
    "\n",
    "<code>pip install --user rasterio</code>\n",
    "\n",
    "\n",
    "4.Still errors.....\n",
    "\n",
    "\n",
    "<code>ERROR: A GDAL API version must be specified. Provide a path to gdal-config using a GDAL_CONFIG environment variable or use a GDAL_VERSION environment variable.\n",
    "</code>\n",
    "\n",
    "\n",
    "5.Try Removing gdal and instal geopandas.\n",
    "\n",
    "<code>conda remove gdal</code>\n",
    "\n",
    "<code>conda install geopandas</code>\n",
    "\n",
    "\n",
    "\n",
    "Stuck at installing numba -> \n",
    "\n",
    "<code>defaults/win-64::numba==0.36.2=np114py36h12cb543_0</code>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "6.Create new conda environment\n",
    "\n",
    "<code>conda create --name skyfolks-env</code>\n",
    "\n",
    "<code>conda activate myenv</code>\n",
    "\n",
    "<code>conda install -c conda-forge geopandas</code>\n",
    "\n",
    "Still failing....\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "7.Reboot and Clean everything \n",
    "\n",
    "<code>conda update --all</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 352\n",
    "n_channels = 3\n",
    "model_save_path = 'test_model.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Reading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REUSE dataset generator and augmentations from Examples\n",
    "Link: https://github.com/nasa/spaceapps-phenomena_detection/blob/dev/examples/ml_model_demo_1.ipynb\n",
    "\n",
    "Apply the logic to the Hurricane Dataset | Transverse Cirrus Bands (TCB)\n",
    "\n",
    "\n",
    "This is used to push subsets of input images in memory for Keras so that there is no out of memory error during Training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetGenerator(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "\n",
    "    def __init__(self, data_path,\n",
    "                 to_fit=True, batch_size=1, dim=(256, 256),\n",
    "                 n_channels=3, shuffle=True, augment=True):\n",
    "        'Initialization'\n",
    "        self.data_path = data_path\n",
    "        self.tif_list = []\n",
    "        self.mask_list = []\n",
    "        for filename in glob(f'{data_path}*.tif*'):\n",
    "            self.tif_list.append(filename)\n",
    "\n",
    "        self.to_fit = to_fit\n",
    "        self.augment = augment\n",
    "        self.batch_size = batch_size\n",
    "        self.dim = dim\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.n = 0\n",
    "        self.max = self.__len__()\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.tif_list) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.tif_list))\n",
    "        if self.shuffle is True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index *\n",
    "                               self.batch_size: (index + 1) * self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        tif_list_temp = [self.tif_list[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X = self._generate_X(tif_list_temp)\n",
    "\n",
    "        #  preprocess and augment data\n",
    "\n",
    "        if self.to_fit:\n",
    "            y = self._generate_y(tif_list_temp)\n",
    "\n",
    "            if self.augment:\n",
    "                seq = make_augmentations()\n",
    "                images_aug = list()\n",
    "                labels_aug = list()\n",
    "                for i in range(len(X)):\n",
    "                    image, label = seq(\n",
    "                        image=X[i].astype('float32'),\n",
    "                        segmentation_maps=np.expand_dims(\n",
    "                            y[i], 0).astype('uint8')\n",
    "                    )\n",
    "                    images_aug.append(image)\n",
    "                    labels_aug.append(label[0, :, :, :])\n",
    "\n",
    "                return np.array(images_aug), np.array(labels_aug)\n",
    "            else:\n",
    "                # import ipdb; ipdb.set_trace()\n",
    "                return X, y[:,:,:,0]\n",
    "\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def _generate_X(self, tif_list_temp):\n",
    "        'Generates data containing batch_size images'\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(tif_list_temp):\n",
    "            # Store sample\n",
    "            X[i, ] = _load_tif_image(ID, self.dim)\n",
    "\n",
    "        return X\n",
    "\n",
    "    def _generate_y(self, tif_list_temp):\n",
    "        'Generates data containing batch_size masks'\n",
    "        y = np.empty((self.batch_size, *self.dim, 1), dtype='float32')\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(tif_list_temp):\n",
    "            # replace tif/tiff with the _bitmap.png or .bmp, depending on the dataset\n",
    "            # to look for corresponding masks for the imput images\n",
    "            y[i, ] = _load_grayscale_image(ID.replace(\n",
    "                '.tiff', '_bitmap.png'), self.dim\n",
    "            )\n",
    "\n",
    "        return y\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.n >= self.max:\n",
    "            self.n = 0\n",
    "        result = self.__getitem__(self.n)\n",
    "        self.n += 1\n",
    "        return result\n",
    "\n",
    "\n",
    "def _load_grayscale_image(image_path, dim):\n",
    "    'Load grayscale image'\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = img / 255\n",
    "\n",
    "    return np.expand_dims(cv2.resize(img, dim), -1)\n",
    "\n",
    "\n",
    "def _load_tif_image(image_path, dim):\n",
    "    'load tif image'\n",
    "\n",
    "    with rasterio.open(image_path, 'r') as data:\n",
    "        return cv2.resize(\n",
    "            np.moveaxis(data.read(), 0, -1), dim\n",
    "        )\n",
    "\n",
    "\n",
    "def sometimes(aug):\n",
    "    return iaa.Sometimes(0.5, aug)\n",
    "\n",
    "def make_augmentations():\n",
    "\n",
    "    return iaa.Sequential([\n",
    "        sometimes(iaa.CoarseDropout(0.1, size_percent=0.2)),\n",
    "        sometimes(\n",
    "            iaa.Affine(\n",
    "                scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)},\n",
    "                # scale images to 80-120% of their size,\n",
    "                # individually per axis\n",
    "                translate_percent={\n",
    "                    \"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\n",
    "                # translate by -20 to +20 percent (per axis)\n",
    "                # rotate by -45 to +45 degrees\n",
    "                rotate=(-10, 10),\n",
    "                shear=(-5, 5),  # shear by -16 to +16 degrees\n",
    "            ),\n",
    "        ),\n",
    "        sometimes(iaa.ElasticTransformation(alpha=10, sigma=1))\n",
    "    ],\n",
    "        random_order=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 352, 352, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 352, 352, 24) 672         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 352, 352, 24) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 352, 352, 24) 5208        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 352, 352, 24) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 352, 352, 24) 5208        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 176, 176, 24) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 176, 176, 24) 96          max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 176, 176, 24) 5208        batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 176, 176, 24) 96          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 176, 176, 24) 5208        batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 176, 176, 24) 96          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 176, 176, 24) 5208        batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 88, 88, 24)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 88, 88, 24)   96          max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 88, 88, 24)   5208        batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 88, 88, 24)   96          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 88, 88, 24)   5208        batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 88, 88, 24)   96          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 88, 88, 24)   5208        batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 44, 44, 24)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 44, 44, 24)   96          max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 44, 44, 24)   5208        batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 44, 44, 24)   96          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 44, 44, 24)   5208        batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 44, 44, 24)   96          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 88, 88, 24)   5208        batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 88, 88, 48)   0           conv2d_transpose[0][0]           \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 88, 88, 48)   192         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 88, 88, 32)   13856       batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 88, 88, 32)   128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 88, 88, 24)   6936        batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 88, 88, 24)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 176, 176, 24) 5208        batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 176, 176, 48) 0           conv2d_transpose_1[0][0]         \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 176, 176, 48) 192         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 176, 176, 32) 13856       batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 176, 176, 32) 128         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 176, 176, 24) 6936        batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 176, 176, 24) 96          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 352, 352, 24) 5208        batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 352, 352, 48) 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 352, 352, 48) 192         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 352, 352, 32) 13856       batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 352, 352, 32) 128         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 352, 352, 24) 6936        batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 352, 352, 1)  25          conv2d_16[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 132,985\n",
      "Trainable params: 131,881\n",
      "Non-trainable params: 1,104\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_layers = 2\n",
    "input_shape = (input_size, input_size, 3)\n",
    "inputs = Input(input_shape)\n",
    "\n",
    "def bn_conv_relu(input, filters, bachnorm_momentum, **conv2d_args):\n",
    "    x = BatchNormalization(momentum=bachnorm_momentum)(input)\n",
    "    x = Conv2D(filters, **conv2d_args)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def bn_upconv_relu(input, filters, bachnorm_momentum, **conv2d_trans_args):\n",
    "    x = BatchNormalization(momentum=bachnorm_momentum)(input)\n",
    "    x = Conv2DTranspose(filters, **conv2d_trans_args)(x)\n",
    "    return x\n",
    "\n",
    "filters = 24\n",
    "upconv_filters = 32\n",
    "\n",
    "kernel_size = (3, 3)\n",
    "activation = 'relu'\n",
    "strides = (1, 1)\n",
    "padding = 'same'\n",
    "kernel_initializer = 'he_normal'\n",
    "output_activation = 'sigmoid'\n",
    "\n",
    "conv2d_args = {\n",
    "    'kernel_size': kernel_size,\n",
    "    'activation': activation,\n",
    "    'strides': strides,\n",
    "    'padding': padding,\n",
    "    'kernel_initializer': kernel_initializer\n",
    "}\n",
    "\n",
    "conv2d_trans_args = {\n",
    "    'kernel_size': kernel_size,\n",
    "    'activation': activation,\n",
    "    'strides': (2, 2),\n",
    "    'padding': padding,\n",
    "}\n",
    "\n",
    "bachnorm_momentum = 0.01\n",
    "\n",
    "pool_size = (2, 2)\n",
    "pool_strides = (2, 2)\n",
    "pool_padding = 'valid'\n",
    "\n",
    "maxpool2d_args = {\n",
    "    'pool_size': pool_size,\n",
    "    'strides': pool_strides,\n",
    "    'padding': pool_padding,\n",
    "}\n",
    "\n",
    "x = Conv2D(filters, **conv2d_args)(inputs)\n",
    "c1 = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n",
    "x = bn_conv_relu(c1, filters, bachnorm_momentum, **conv2d_args)\n",
    "x = MaxPooling2D(**maxpool2d_args)(x)\n",
    "\n",
    "down_layers = []\n",
    "\n",
    "for l in range(num_layers):\n",
    "    x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n",
    "    x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n",
    "    down_layers.append(x)\n",
    "    x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n",
    "    x = MaxPooling2D(**maxpool2d_args)(x)\n",
    "\n",
    "x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n",
    "x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n",
    "x = bn_upconv_relu(x, filters, bachnorm_momentum, **conv2d_trans_args)\n",
    "\n",
    "for conv in reversed(down_layers):\n",
    "    x = concatenate([x, conv])\n",
    "    x = bn_conv_relu(\n",
    "        x, upconv_filters, bachnorm_momentum, **conv2d_args\n",
    "    )\n",
    "    x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n",
    "    x = bn_upconv_relu(\n",
    "        x, filters, bachnorm_momentum, **conv2d_trans_args\n",
    "    )\n",
    "\n",
    "x = concatenate([x, c1])\n",
    "x = bn_conv_relu(x, upconv_filters, bachnorm_momentum, **conv2d_args)\n",
    "x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n",
    "\n",
    "outputs = Conv2D(\n",
    "    1,\n",
    "    kernel_size=(1, 1),\n",
    "    strides=(1, 1),\n",
    "    activation=output_activation,\n",
    "    padding='valid')(x)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotLearning(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.acc = []\n",
    "        self.val_acc = []\n",
    "        self.fig = plt.figure()\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.acc.append(logs.get('accuracy'))\n",
    "        self.val_acc.append(logs.get('val_accuracy'))\n",
    "        self.i += 1\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        ax1.set_yscale('log')\n",
    "        ax1.plot(self.x, self.losses, label=\"loss\")\n",
    "        ax1.plot(self.x, self.val_losses, label=\"val_loss\")\n",
    "        ax1.legend()\n",
    "        \n",
    "        ax2.plot(self.x, self.acc, label=\"accuracy\")\n",
    "        ax2.plot(self.x, self.val_acc, label=\"validation accuracy\")\n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.show();\n",
    "\n",
    "pl = PlotLearning()\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=20,\n",
    "                  verbose=1, mode=\"auto\"),\n",
    "    ModelCheckpoint(filepath=model_save_path,\n",
    "                    verbose=1, save_best_only=True),\n",
    "    pl,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(\n",
    "                learning_rate=0.0001,\n",
    "                beta_1=0.9,\n",
    "                beta_2=0.999,\n",
    "                epsilon=1e-07,\n",
    "                amsgrad=False,\n",
    "            ),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_generator = UnetGenerator('data/hld-data/train', batch_size=4)\n",
    "val_generator = UnetGenerator('data/hld-data/val', batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.UnetGenerator at 0x1a0dac6f1c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2600 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'logs' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-1bd248a3e0ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m results = model.fit_generator(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1813\u001b[0m     \"\"\"\n\u001b[0;32m   1814\u001b[0m     \u001b[0m_keras_api_gauge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fit_generator'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1815\u001b[1;33m     return self.fit(\n\u001b[0m\u001b[0;32m   1816\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1817\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1104\u001b[1;33m         \u001b[0mepoch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m         \u001b[1;31m# Run validation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'logs' referenced before assignment"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=200,\n",
    "    steps_per_epoch=13,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks,\n",
    "    validation_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_generator = UnetGenerator('data/hld-data/val',\n",
    "    batch_size=4,\n",
    "    augment=True\n",
    ")\n",
    "random_batch = np.random.randint(low=0, high=9)\n",
    "for batch_index, batch_data in enumerate(val_generator):\n",
    "    if batch_index == random_batch:\n",
    "        (modis_batch, bmp_batch) = batch_data\n",
    "        bmp_predict_batch = model.predict(modis_batch)\n",
    "        #fig, axes = plt.subplots()\n",
    "        for j in range(len(modis_batch)):\n",
    "            f, ax = plt.subplots(1, 3, constrained_layout=True, dpi=100)\n",
    "            ax[0].imshow(modis_batch[j].astype('uint8'))\n",
    "            ax[0].set_title('RGB Image')\n",
    "            ax[0].xaxis.set_ticks([])\n",
    "            ax[0].yaxis.set_ticks([])\n",
    "            ax[1].imshow(modis_batch[j].astype('uint8'))\n",
    "            ax[1].xaxis.set_ticks([])\n",
    "            ax[1].yaxis.set_ticks([])\n",
    "            ax[1].set_title('SME label overlay')\n",
    "            ax[2].imshow(modis_batch[j].astype('uint8'))\n",
    "            ax[2].set_title('Model Prediction overlay')\n",
    "            ax[2].xaxis.set_ticks([])\n",
    "            ax[2].yaxis.set_ticks([])\n",
    "            bmp_data = bmp_batch[j].astype('uint8')\n",
    "            ax[1].imshow(ma.masked_where(bmp_data != 1, bmp_data)[:,:,0],alpha=0.35,cmap='Purples')\n",
    "            ax[2].imshow(ma.masked_where(bmp_predict_batch[j] < 0.5, bmp_predict_batch[j])[:,:,0],alpha=0.45,cmap='spring')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Test and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAZAR-PREDICTION-SERVICE\n",
    "\n",
    "##### Logic steps\n",
    "\n",
    "1. Expose Endpoint using Flask\n",
    "\n",
    "2. Receive Request in JSON\n",
    "\n",
    "3. Call MODIS to retrieve image for X,Y\n",
    "\n",
    "4. Run Image by previous Model\n",
    "\n",
    "5. Return Results in JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
